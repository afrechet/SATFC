{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "%matplotlib inline\n",
    "\n",
    "import importlib\n",
    "import glob\n",
    "import simulatorutils\n",
    "import pandas as pd\n",
    "importlib.reload(simulatorutils)\n",
    "from simulatorutils import MultiBandAuctionState, VCGState\n",
    "import os\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import operator\n",
    "import subprocess\n",
    "import matplotlib.colors as colors\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "\n",
    "import tempfile\n",
    "from matplotlib.patches import Rectangle\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from collections import defaultdict\n",
    "from matplotlib import rc\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s:%(message)s', level=logging.DEBUG, datefmt='%I:%M:%S')\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "from scipy.stats import wilcoxon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIGDIR = '/ubc/cs/research/arrow/satfc/satfc-scripts/simulator/newish/newest/figures'\n",
    "COST = 'Total Cost'\n",
    "EFFICIENCY = 'Total Value Loss'\n",
    "\n",
    "DEFAULT_MARKERSIZE = 120\n",
    "MARKERSIZE = DEFAULT_MARKERSIZE\n",
    "sns.set(font_scale=4, style='whitegrid')\n",
    "FIGSIZE = (18,12)\n",
    "\n",
    "RASTERIZE_POINTS = False\n",
    "\n",
    "normalized = True\n",
    "# op = operator.sub \n",
    "op = operator.truediv\n",
    "means_only = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limits_from_frame(df, reference_type='FCC'):\n",
    "    df = df.reset_index().copy().set_index(['auction', 'model', 'UHF_Only'])\n",
    "    reference_type = df.query(f'type == \"{reference_type}\"')\n",
    "#     display(reference_type)\n",
    "    top = (df[COST] / reference_type[COST]).max()\n",
    "    bottom = (df[COST] / reference_type[COST]).min()\n",
    "    left = (df[EFFICIENCY] / reference_type[EFFICIENCY]).min()\n",
    "    right = (df[EFFICIENCY] / reference_type[EFFICIENCY]).max()\n",
    "    print((left, right, top, bottom))\n",
    "    return (left, right, bottom, top)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def special_save_fig(fig, file_name, fmt=None, dpi=300, tight=True):\n",
    "    \"\"\"Save a Matplotlib figure as EPS/PNG/PDF to the given path and trim it.\n",
    "    \"\"\"\n",
    "    if not fmt:\n",
    "        fmt = file_name.strip().split('.')[-1]\n",
    "\n",
    "    if fmt not in ['eps', 'png', 'pdf']:\n",
    "        raise ValueError('unsupported format: %s' % (fmt,))\n",
    "\n",
    "    extension = '.%s' % (fmt,)\n",
    "    if not file_name.endswith(extension):\n",
    "        file_name += extension\n",
    "\n",
    "    file_name = os.path.abspath(file_name)\n",
    "    \n",
    "    with tempfile.NamedTemporaryFile() as tmp_file:\n",
    "        tmp_name = tmp_file.name + extension\n",
    "\n",
    "    # save figure\n",
    "    if tight:\n",
    "        fig.savefig(tmp_name, dpi=dpi, bbox_inches='tight')\n",
    "    else:\n",
    "        fig.savefig(tmp_name, dpi=dpi)\n",
    "\n",
    "    #trim it\n",
    "    if fmt == 'eps':\n",
    "        subprocess.call('epstool --bbox --copy %s %s' %\n",
    "                        (tmp_name, file_name), shell=True)\n",
    "    elif fmt == 'png':\n",
    "        subprocess.call('convert %s -trim %s' %\n",
    "                        (tmp_name, file_name), shell=True)\n",
    "    elif fmt == 'pdf':\n",
    "        subprocess.call('pdfcrop %s %s' % (tmp_name, file_name), shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_to_extra(d, name, include_label=True):\n",
    "    retval = dict(d.get(name, {}))\n",
    "    retval['label'] = retval.get('label', name)\n",
    "    if not include_label:\n",
    "        del retval['label']\n",
    "    return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting_code(FRAMES, normalized, d, op=operator.truediv, means=True, means_only=False, color_is_stage=False):\n",
    "    cNorm  = colors.Normalize(vmin=1, vmax=9)\n",
    "    cmap = plt.cm.get_cmap('tab10', 9)\n",
    "    base_kwargs = dict()\n",
    "    if color_is_stage:\n",
    "        base_kwargs['cmap'] = cmap\n",
    "        base_kwargs['norm'] = cNorm\n",
    "    \n",
    "    baseline = FRAMES[0]\n",
    "    fig = plt.figure(figsize=FIGSIZE)\n",
    "    for ii, frame in enumerate(FRAMES):\n",
    "        name = frame['type'].unique()[0]\n",
    "        if normalized:         \n",
    "            if not means_only and ii > 0:\n",
    "                scatter = plt.scatter(x=op(frame[EFFICIENCY], baseline[EFFICIENCY]), y=op(frame[COST],baseline[COST]), sizes=[MARKERSIZE]*len(frame), **name_to_extra(d, name), alpha=0.6, rasterized=RASTERIZE_POINTS, zorder=10)\n",
    "                scatter.set_clip_on(False)\n",
    "            if means or ii == 0:\n",
    "                mean_eff = op(frame[EFFICIENCY].mean(), baseline[EFFICIENCY].mean())\n",
    "                mean_cost = op(frame[COST].mean(), baseline[COST].mean())\n",
    "                print(f\"Mean value loss of {name} is {mean_eff} of reference. Mean cost is {mean_cost} of reference\")\n",
    "                extra_args = name_to_extra(d, name, include_label=means_only or ii==0)\n",
    "                if 'marker' in extra_args:\n",
    "                    del extra_args['marker']\n",
    "                if 'facecolor' in extra_args:\n",
    "                    del extra_args['facecolor']\n",
    "                scatter = plt.scatter(x=[mean_eff], y=[mean_cost], sizes=[MARKERSIZE*8], marker='*' if ii > 0 else 'd',rasterized=RASTERIZE_POINTS, zorder=10, **extra_args)\n",
    "                scatter.set_clip_on(False)\n",
    "        else:\n",
    "            if means:\n",
    "                extra_args = name_to_extra(d, name, include_label=means_only)\n",
    "                if 'marker' in extra_args:\n",
    "                    del extra_args['marker']\n",
    "                if 'facecolor' in extra_args:\n",
    "                    del extra_args['facecolor']\n",
    "                scatter = plt.scatter(x=frame[EFFICIENCY].mean(), y=frame[COST].mean(), sizes=[MARKERSIZE*5], marker='*',rasterized=RASTERIZE_POINTS, zorder=10, **extra_args)\n",
    "                scatter.set_clip_on(False)\n",
    "            if not means_only:\n",
    "                kwargs = dict(base_kwargs)\n",
    "\n",
    "                tmp = name_to_extra(d, name)                \n",
    "                    \n",
    "                scatter = plt.scatter(x=frame[EFFICIENCY], y=frame[COST], sizes=[MARKERSIZE]*len(frame), rasterized=RASTERIZE_POINTS, **tmp, zorder=10, **kwargs)\n",
    "                scatter.set_clip_on(False)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_normalized(df, baseline, op=operator.truediv, set_limits=True):\n",
    "    '''Limits is (left, right, top, bottom) tuple or None'''\n",
    "    op_to_rep = {operator.truediv: '/', operator.sub: '(Billions) -'}\n",
    "    ax = plt.gca()\n",
    "    baseline_name = baseline['type'].unique()[0]\n",
    "    if op == operator.truediv:\n",
    "        plt.xlabel(f'Normalized Value Loss')\n",
    "        plt.ylabel(f'Normalized Cost')\n",
    "#         plt.xlabel(f'Value Loss {op_to_rep[op]} {baseline_name} Value Loss')\n",
    "#         plt.ylabel(f'Cost {op_to_rep[op]} {baseline_name} Cost')\n",
    "    else:\n",
    "        plt.xlabel(f'Value Loss {op_to_rep[op]} {baseline_name} Value Loss')\n",
    "        plt.ylabel(f'Cost {op_to_rep[op]} FCC Cost')\n",
    "    \n",
    "    if set_limits:\n",
    "        FUDGE = 0.005 if op is operator.truediv else 0.1e9\n",
    "        plt.xlim(left=op(df[EFFICIENCY], baseline[EFFICIENCY]).min() - FUDGE, right=max(FUDGE, op(df[EFFICIENCY], baseline[EFFICIENCY]).max() + FUDGE))\n",
    "        plt.ylim(bottom=op(df[COST], baseline[COST]).min() - FUDGE, top=max(op(df[COST], baseline[COST]).max() + FUDGE, FUDGE))\n",
    "    \n",
    "    # Add dotted lines\n",
    "    plt.vlines(1, ax.get_ylim()[0], ax.get_ylim()[1], alpha=0.5, clip_on=False, linestyles='--')\n",
    "    plt.hlines(1, ax.get_xlim()[0], ax.get_xlim()[1], alpha=0.5, clip_on=False,linestyles='--')\n",
    "    \n",
    "    if op == operator.sub:\n",
    "        ax.xaxis.set_major_formatter(FuncFormatter(lambda x,y : str(x/1e9)))\n",
    "        ax.yaxis.set_major_formatter(FuncFormatter(lambda x,y : str(x/1e9)))   \n",
    "\n",
    "#     plt.axis('scaled')\n",
    "    \n",
    "def format_unnormalized(set_limits=True):\n",
    "    ax = plt.gca()\n",
    "    plt.xlabel('Value Loss (Billions)')\n",
    "    plt.ylabel('Cost (Billions)')\n",
    "    plt.ylim(bottom=0)\n",
    "    plt.xlim(left=0)\n",
    "    ax.xaxis.set_major_formatter(FuncFormatter(lambda x,y : str(x/1e9)))\n",
    "    ax.yaxis.set_major_formatter(FuncFormatter(lambda x,y : str(x/1e9)))   \n",
    "    \n",
    "def format_figure(df, baseline, normalized, d, op=operator.truediv, limits=None, fixed_legend=False):\n",
    "    if limits is not None:\n",
    "        if len(limits) != 4:\n",
    "            raise ValueError(\"Expected left right top bottom tuple\")\n",
    "        plt.xlim(left=limits[0], right=limits[1])\n",
    "        plt.ylim(bottom=limits[2], top=limits[3])\n",
    "    \n",
    "    if normalized:\n",
    "        format_normalized(df, baseline, op, set_limits=limits is None)\n",
    "    else:\n",
    "        format_unnormalized(set_limits=limits is None)\n",
    "    \n",
    "    if limits is None:\n",
    "        print(plt.gca().get_xlim(), plt.gca().get_ylim())\n",
    "        \n",
    "#     plt.legend(loc='best')\n",
    "    axis = plt.gca()\n",
    "    handles, labels = axis.get_legend_handles_labels()\n",
    "    \n",
    "#     for h, l in zip(handles, labels):\n",
    "#         handles = mlines.Line2D([], [], color='black', marker='*', linestyle='None',\n",
    "#                           markersize=10, label='Blue stars')\n",
    "\n",
    "    \n",
    "#         c = 'red'\n",
    "#     #     c = None\n",
    "#     #     for k in d.keys():\n",
    "#     #         if d[k]['label'] == labels[0]:\n",
    "#     #             c = d[k]['color']\n",
    "#     #             break\n",
    "#     #     if c is None:\n",
    "#     #         raise ValueError()\n",
    "\n",
    "#         handles[0] = mpatches.Patch(color=c)\n",
    "    \n",
    "    \n",
    "    # Sort according to efficiency\n",
    "    if len(labels) > 1 and not fixed_legend:\n",
    "        mean_eff = df.groupby(level=0)[EFFICIENCY].mean().sort_values().index.values\n",
    "        order = []\n",
    "        for l in mean_eff:\n",
    "            try:\n",
    "                order.append(labels.index(l))\n",
    "            except Exception as e:\n",
    "                order.append(labels.index(d[l]['label']))\n",
    "        order = np.array(order)\n",
    "    else:\n",
    "#         order = np.array(list(range(len(labels))))\n",
    "        order = np.argsort(labels)\n",
    "        print(order)\n",
    "    \n",
    "#     if normalized:\n",
    "#         labels[0] = '$$\\textbf{lab}$$'\n",
    "\n",
    "    \n",
    "    legend = axis.legend(handles=list(np.array(handles)[order]),labels=list(np.array(labels)[order]), loc='best') \n",
    "\n",
    "#     legend = axis.legend(handles=list(np.array(handles)[order]),labels=list(np.array(labels)[order]), loc='best') \n",
    "    \n",
    "def save_fig(name, normalized, op, means_only=False, uhf_only=False, fig=None, model=None):\n",
    "    op_to_rep = {operator.truediv: 'relative', operator.sub: 'absolute'}\n",
    "    fname = name\n",
    "    if normalized:\n",
    "        fname += f'_{op_to_rep[op]}'\n",
    "    if means_only:\n",
    "        fname += '_means_only'\n",
    "    if model:\n",
    "        fname += '_' + model\n",
    "    if uhf_only:\n",
    "        fname += '_UHF_ONLY'\n",
    "    special_save_fig(fig, os.path.join(FIGDIR, f'{fname}.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_experiment(folders, skip_failures=False, delete_failures=False, count_rounds=False, end_only=True, extra=None, specific_end_stage=None, return_states=False, limit=None):\n",
    "    records = []\n",
    "    states = []\n",
    "    if count_rounds and end_only:\n",
    "        raise ValueError(\"Count rounds only works if end only is set to false\")\n",
    "    for auction_folder in tqdm(folders):\n",
    "        try:\n",
    "            basename = os.path.basename(auction_folder)\n",
    "            seed = int(basename.split('_')[-1])\n",
    "            auction_type = auction_folder.split('/')[-2]\n",
    "            is_vcg = 'VCG' in auction_type\n",
    "            if is_vcg:\n",
    "                state = VCGState(auction_folder, all_stations=STATIONS, allow_intermediate=True)\n",
    "            else:\n",
    "                state = MultiBandAuctionState(auction_folder, end_only=end_only, specific_end_stage=specific_end_stage)\n",
    "            cost = state.total_cost()\n",
    "            value_loss = state.total_value_loss()\n",
    "            record = {\n",
    "                'auction': seed,\n",
    "                'type': auction_type,\n",
    "                'Total Cost': cost,\n",
    "                'Total Value Loss': value_loss,\n",
    "                'UHF_Only': 'UHF_ONLY' in auction_folder,\n",
    "                'model': 'pop' if '_POP' in auction_folder else 'ulrich',\n",
    "                'walltime': state.walltime(),\n",
    "                'cputime': state.cputime(),\n",
    "                'Final Stage': 1 if is_vcg else state.ending_stage()\n",
    "            }\n",
    "            if count_rounds:\n",
    "                record['n_rounds'] = state.n_rounds()\n",
    "            if extra is not None:\n",
    "                for k,v in extra.items():\n",
    "                    record[k] = v(state)\n",
    "            records.append(record)\n",
    "            if return_states:\n",
    "                states.append(state)\n",
    "        \n",
    "        except Exception as e:\n",
    "            if isinstance(e, KeyboardInterrupt): # Want to be able to use stop button\n",
    "                raise\n",
    "            if delete_failures:\n",
    "                print(f\"Deleting {auction_folder}\")\n",
    "                !rm -rf {auction_folder}\n",
    "            elif skip_failures:\n",
    "                print(f\"Skipping {auction_folder}\")\n",
    "            else:\n",
    "                raise\n",
    "                \n",
    "        if limit is not None and len(records) > limit:\n",
    "            break\n",
    "    df = pd.DataFrame.from_records(records)\n",
    "    df = df.set_index(['type', 'auction'])\n",
    "    if return_states:\n",
    "        return df.sort_index(), states\n",
    "    else:\n",
    "        return df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_frames(df, types=None, reference_types=None):\n",
    "    if reference_types is None:\n",
    "        reference_types = ['FCC', '29']\n",
    "    if types is None:\n",
    "        types = df.index.get_level_values(0).unique().values.tolist()\n",
    "    else:\n",
    "        types = list(types)\n",
    "    q = [t for t in types if t in reference_types]\n",
    "    if len(q) > 0: # Ensure FCC is always first\n",
    "        types.remove(q[0])\n",
    "        types = [q[0]] + types\n",
    "    return [df.reset_index()[df.reset_index()['type'] == x].sort_values('auction').set_index('auction') for x in types if x in df.reset_index()['type'].unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_folders(path, uhf_only=False):\n",
    "    path += '*/*/*'\n",
    "    return glob.glob(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_pallet(types):\n",
    "    d = dict()\n",
    "    for i, t in enumerate(types):\n",
    "        d[t] = dict(PALLET[i])\n",
    "    return d\n",
    "\n",
    "def standard_analysis(d, name, df, types=None, reference_types=None, means=None, means_only=None, limits=None, stages=None, model=False, save=True, fixed_legend=False):\n",
    "    if means is None:\n",
    "        means = True\n",
    "    if means_only is None:\n",
    "        means_only = False\n",
    "    if stages is None:\n",
    "        stages = False\n",
    "        \n",
    "    if df['Final Stage'].nunique() > 1:\n",
    "        logging.info(f\"Multiple stages detected {df['Final Stage'].unique()}\")\n",
    "        if not stages:\n",
    "            logging.warning(\"Not showing the difference between stages!\")\n",
    "        if normalized:\n",
    "            # Most of the time meaningless because you actually care about AMOUNT cleared which somehow isn't in your stupid JSON\n",
    "            logging.warning(\"Potentially you are trying a normalized comparison with different amounts of spectrum!\")\n",
    "\n",
    "    FRAMES = make_frames(df, types=types, reference_types=reference_types)\n",
    "    if df['UHF_Only'].nunique() > 1 and not name.startswith('vhf'):\n",
    "        raise ValueError(\"DF mixes UHF only and non-UHF only\")\n",
    "    uhf_only = df['UHF_Only'].all()\n",
    "    if df['model'].nunique() > 1:\n",
    "        raise ValueError(f\"DF mixes value models! {df['model'].unique()}\")\n",
    "    \n",
    "    fig = plotting_code(FRAMES, normalized, d, op=op, means_only=means_only, means=means, color_is_stage=stages)\n",
    "    format_figure(df, FRAMES[0], normalized, d, op=op, limits=limits, fixed_legend=fixed_legend) \n",
    "    if save:\n",
    "#         plt.legend(loc='upper left')\n",
    "        save_fig(name, normalized, op, means_only=means_only, uhf_only=uhf_only, fig=fig, model=df['model'].unique()[0])\n",
    "    \n",
    "def dual_standard_analysis(d, name, df, types=None, reference_types=None, means=None, means_only=None, limits=None, auto_limits=True, save=True, fixed_legend=False):\n",
    "    if auto_limits and limits is None:\n",
    "        limits = limits_from_frame(df, reference_type=reference_types[0] if reference_types is not None else types[0] if types is not None else 'FCC')\n",
    "    for model, gdf in df.groupby('model'):\n",
    "        print(f\"Model {model}\")\n",
    "        uhf_only = gdf.loc[gdf['UHF_Only'] == True]\n",
    "        not_uhf_only = gdf.loc[gdf['UHF_Only'] == False]\n",
    "        kwargs = dict(types=types, reference_types=reference_types, means=means, means_only=means_only, limits=limits, model=model, save=save, fixed_legend=fixed_legend)\n",
    "        if len(uhf_only) > 0:\n",
    "            print(f\"UHF ONLY\")\n",
    "            standard_analysis(d, name, uhf_only, **kwargs)\n",
    "        if len(not_uhf_only) > 0:\n",
    "            print(f\"UHF+VHF\")\n",
    "            standard_analysis(d, name, not_uhf_only, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PALLET = [\n",
    "    {\n",
    "        'color': 'red',\n",
    "        'marker': 'o',\n",
    "        'facecolor': 'none',\n",
    "        'linewidth': 1\n",
    "    },\n",
    "    {\n",
    "        'color': 'blue',\n",
    "        'marker': 's',\n",
    "        'facecolor': 'none',\n",
    "        'linewidth': 1\n",
    "    },\n",
    "    {\n",
    "        'color': 'black',\n",
    "        'marker': '^',\n",
    "        'facecolor': 'none',\n",
    "        'linewidth': 1\n",
    "    },\n",
    "    {\n",
    "        'color': 'green',\n",
    "        'marker': 'D',\n",
    "        'facecolor': 'none',\n",
    "        'linewidth': 1\n",
    "    },\n",
    "    {\n",
    "        'color': 'purple'\n",
    "    },\n",
    "    {\n",
    "        'color': 'orange'\n",
    "    },\n",
    "    {\n",
    "        'color': 'pink'\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_df = parse_experiment(make_folders('/global/scratch/satfc/new_experiments/v6/scoring'), skip_failures=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Interference here is obviously going to including VHF constraints, even in the UHF-only case. I guess that's OK, since they don't vary it either between channels. \n",
    "FCC_SCORING = 'FCC'\n",
    "INTERFERENCE_SCORING = 'Interference'\n",
    "POPULATION_SCORING = 'Population'\n",
    "UNIFORM_SCORING = 'Uniform'\n",
    "\n",
    "HALF_INTERFERENCE = 'HalfInterference'\n",
    "HALF_POPULATION = 'HalfPopulation'\n",
    "# TYPES = [FCC_SCORING, INTERFERENCE_SCORING, POPULATION_SCORING, UNIFORM_SCORING]\n",
    "TYPES = [FCC_SCORING, HALF_INTERFERENCE, HALF_POPULATION, UNIFORM_SCORING]\n",
    "\n",
    "d = standard_pallet(TYPES)\n",
    "d[FCC_SCORING]['label'] = 'Incentive Auction'#r'$\\sqrt{Population} \\cdot \\sqrt{Interference}$'\n",
    "d[HALF_INTERFERENCE]['label'] = 'Interference'\n",
    "d[HALF_POPULATION]['label'] = 'Population'\n",
    "print(f\"CPU time for scoring: {scoring_df.loc[TYPES]['cputime'].sum()}\")\n",
    "\n",
    "\n",
    "dual_standard_analysis(d, 'scoring', scoring_df.loc[TYPES], types=TYPES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeout_df = parse_experiment(make_folders('/global/scratch/satfc/new_experiments/v6/no_price_drop_timeouts'), skip_failures=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TYPES = timeout_df.index.levels[0].values\n",
    "d = standard_pallet(TYPES)\n",
    "d['FCC']['label'] = 'Incentive Auction'\n",
    "d['NO_PRICE_DROPS']['label'] = 'No Freezing on Timeouts'\n",
    "dual_standard_analysis(d, 'timeouts', timeout_df, types=TYPES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stage_df = parse_experiment(make_folders('/global/scratch/satfc/new_experiments/v6/multiple_stages'), skip_failures=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logging.info(f\"CPU time for stages: {stage_df['cputime'].sum()}\")\n",
    "\n",
    "TWENTY_NINE = '29'\n",
    "THIRTY_ONE = '31'\n",
    "THIRTY_TWO = '32'\n",
    "THIRTY_SIX = '36'\n",
    "THIRTY_EIGHT = '38'\n",
    "THIRTY_NINE = '39'\n",
    "FORTY_ONE = '41'\n",
    "\n",
    "THIRTY_ONE_TO_THIRTY_SIX = '31_to_36'\n",
    "TWENTY_NINE_TO_THIRTY_SIX = '29_to_36'\n",
    "\n",
    "TYPES = [TWENTY_NINE, THIRTY_ONE, THIRTY_TWO, THIRTY_SIX, THIRTY_ONE_TO_THIRTY_SIX, TWENTY_NINE_TO_THIRTY_SIX]\n",
    "\n",
    "d = standard_pallet(TYPES)\n",
    "d[TWENTY_NINE]['label'] = '4 Stages'\n",
    "d[THIRTY_ONE]['label'] = '3 Stages'\n",
    "d[THIRTY_TWO]['label'] = '2 Stages'\n",
    "d[THIRTY_SIX]['label'] = '1 Stage'\n",
    "d[TWENTY_NINE_TO_THIRTY_SIX]['label'] = '2 Stages (126, 84)'\n",
    "d[THIRTY_ONE_TO_THIRTY_SIX]['label'] = '2 Stages (114, 84)'\n",
    "\n",
    "no_skipping = stage_df.query(f'type != \"{THIRTY_ONE_TO_THIRTY_SIX}\" and type != \"{TWENTY_NINE_TO_THIRTY_SIX}\"')\n",
    "\n",
    "dual_standard_analysis(d, 'stages_rel36', no_skipping, types=TYPES, reference_types=[THIRTY_SIX], fixed_legend=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(stage_df.loc[TWENTY_NINE].groupby(['model', 'UHF_Only'])[COST].mean() / stage_df.loc[THIRTY_SIX].groupby(['model', 'UHF_Only'])[COST].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_df = parse_experiment(make_folders('/global/scratch/satfc/new_experiments/v6/early_stopping'), skip_failures=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_to_oracle_df = es_df.loc[['Early_0.67', 'SingleStage_0.67', 'Early_1.00', 'SingleStage_1.00']]\n",
    "compare_to_oracle_df = compare_to_oracle_df.reset_index()\n",
    "compare_to_oracle_df['type'] = compare_to_oracle_df['type'].apply(lambda x: x.split('_')[0])\n",
    "compare_to_oracle_df = compare_to_oracle_df.set_index(['type', 'auction'])\n",
    "TYPES = ['SingleStage', 'Early']\n",
    "d = standard_pallet(TYPES)\n",
    "d['Early']['label'] = 'Early Stopping'\n",
    "d['SingleStage']['label'] = 'Single Stage Oracle'\n",
    "dual_standard_analysis(d, f'SSvsES', compare_to_oracle_df, reference_types=['SingleStage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Special limits here...\n",
    "for scale in ['0.33', '0.67', '1.00']:\n",
    "    TYPES = [f'SingleStage_{scale}', f'Early_{scale}']\n",
    "    q = es_df.loc[TYPES]\n",
    "    d = standard_pallet(TYPES)\n",
    "    d[f'Early_{scale}']['label'] = 'Early Stopping'\n",
    "    d[f'SingleStage_{scale}']['label'] = 'Single Stage Oracle'\n",
    "    s = str(float(scale) * 100).strip('0.')\n",
    "    dual_standard_analysis(d, f'SSvsES_{s}', q, types=TYPES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# es_df['Scaling'] = es_df.reset_index()['type'].str.extract('(\\d+\\.?\\d*)').values\n",
    "# es_df['Historic'] = es_df.reset_index()['type'].str.contains(\"Historic\").values\n",
    "# es_df['ScalingHistoric'] = es_df['Scaling'].astype(str) + es_df['Historic'].astype(str)\n",
    "\n",
    "no_ss = es_df.loc[['Early_0.33', 'Early_0.67', 'Early_1.00', 'FCC_0.33', 'FCC_0.67', 'FCC_1.00']].copy()\n",
    "no_ss['Blocks'] = 11 - no_ss['Final Stage']\n",
    "no_ss['Grouping'] = no_ss.reset_index()['type'].apply(lambda x: '_'.join(x.split('_')[1:]).replace(\"Historic\", \"H\")).values\n",
    "no_ss['Early Stopping'] = no_ss.reset_index()['type'].str.contains(\"Early\").apply(lambda x: 'Yes' if x else 'No').values\n",
    "no_ss['$/Block'] = no_ss[COST] / (11 - no_ss['Final Stage'])\n",
    "no_ss['Value Loss / Block'] = no_ss[EFFICIENCY] / no_ss['Blocks']\n",
    "\n",
    "no_ss['Grouping'] = no_ss['Grouping'].apply(lambda x: '1.00 (Pop)' if x == '1.00' else x)\n",
    "\n",
    "no_ss['Mobile Licenses'] = no_ss['Blocks']\n",
    "\n",
    "final_df = no_ss[no_ss['Grouping'].isin(['0.67', '1.00 (Pop)'])]\n",
    "\n",
    "pivot = final_df.reset_index().pivot_table(index=['auction', 'Grouping'],columns='Early Stopping', values='Mobile Licenses')\n",
    "pivot['Diff'] = pivot['Yes'] - pivot['No']\n",
    "# pivot['Diff'].po09\n",
    "\n",
    "# for g, df in final_df.groupby('Grouping'):\n",
    "#     display(df.melt(id_vars='Grouping', value_vars='Mobile Licenses'))\n",
    "\n",
    "# for g, df in final_df.groupby(['Grouping', 'Early Stopping']):\n",
    "#     print(g, df['Mobile Licenses'].mean())\n",
    "\n",
    "\n",
    "# plt.figure(figsize=FIGSIZE)\n",
    "# for g, df in final_df.groupby(['Grouping', 'Early Stopping']):\n",
    "#     s = ECDF(df['Mobile Licenses'])\n",
    "#     plt.plot(s.x, s.y, label=g, linestyle='--' if g[0] == '0.67' else '-', color='r' if g[1] == 'Yes' else 'b')\n",
    "# plt.xlabel('Mobile Licenses')\n",
    "# plt.ylabel('Fraction of Simulations')\n",
    "# plt.legend()\n",
    "# g = sns.catplot(x='Grouping', y='Mobile Licenses', hue='Early Stopping', data=final_df, height=15, jitter=True)\n",
    "\n",
    "# special_save_fig(g, os.path.join(FIGDIR,'ES_Blocks.pdf'))\n",
    "\n",
    "# g = sns.catplot(x=\"Grouping\", y=\"$/Block\", hue=\"Early Stopping\", data=es_df, height=15, kind=\"bar\")\n",
    "# special_save_fig(g, os.path.join(FIGDIR,'ES_DollarBlock.pdf'))\n",
    "# g = sns.catplot(x=\"Grouping\", y=\"Value Loss / Block\", hue=\"Early Stopping\", data=es_df, height=15, kind=\"bar\")\n",
    "# special_save_fig(g, os.path.join(FIGDIR,'ValueLossBlock.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# es_df.loc['Early_0.67'].groupby(['model', 'UHF_Only'])[COST].mean() / es_df.loc['SingleStage_0.67'].groupby(['model', 'UHF_Only'])[COST].mean()\n",
    "# es_df.loc['Early_0.67'].groupby(['model', 'UHF_Only'])[EFFICIENCY].mean() / es_df.loc['SingleStage_0.67'].groupby(['model', 'UHF_Only'])[EFFICIENCY].mean()\n",
    "\n",
    "# 1/(es_df.loc['Early_1.00'].groupby(['model', 'UHF_Only'])[COST].mean() / es_df.loc['SingleStage_1.00'].groupby(['model', 'UHF_Only'])[COST].mean())\n",
    "# 1/(es_df.loc['Early_1.00'].groupby(['model', 'UHF_Only'])[EFFICIENCY].mean() / es_df.loc['SingleStage_1.00'].groupby(['model', 'UHF_Only'])[EFFICIENCY].mean())\n",
    "\n",
    "es_df.loc[['Early_0.67', 'Early_1.00', 'FCC_0.67', 'FCC_1.00', 'SingleStage_0.67', 'SingleStage_1.00']]['cputime'].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fc_df = parse_experiment(make_folders('/global/scratch/satfc/new_experiments/v6/Afeasibility_checker'), skip_failures=True)\n",
    "fc_df = fc_df.query(f\"type != '{SATFC_PLUS_CPLEX}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(fc_df.loc[GNOVELTY].groupby(['model', 'UHF_Only'])[COST].mean() / fc_df.loc['FCC'].groupby(['model', 'UHF_Only'])[COST].mean()).max()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fc_df = fc_df.drop(['FCC', 'FCC2', 'FCC_PLUS_CPLEX_V2'], level=0)\n",
    "# fc_df = fc_df.rename(index={'FCC3': 'FCC'})\n",
    "fc_df.reset_index()['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_df['cputime'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SATFC = 'FCC'\n",
    "GUROBI = 'GUROBI'\n",
    "PICOSAT = 'PICOSAT'\n",
    "GREEDY = 'GREEDY'\n",
    "GNOVELTY = 'GNOVELTY'\n",
    "CPLEX = 'CPLEX'\n",
    "SATFC_PLUS_CPLEX = 'FCC_PLUS_CPLEX_V2'\n",
    "\n",
    "d = {\n",
    "    SATFC: {\n",
    "        'color': 'red',\n",
    "        'label': 'SATFC',\n",
    "#         'zorder': 1000\n",
    "    },\n",
    "    GUROBI: {\n",
    "        'color': 'blue',\n",
    "        'label': 'Gurobi'\n",
    "    },\n",
    "    PICOSAT: {\n",
    "        'color': 'orange',\n",
    "        'label': 'PicoSAT',\n",
    "    },\n",
    "    GREEDY: {\n",
    "        'color': 'green',\n",
    "        'label': 'Greedy'\n",
    "    },\n",
    "    GNOVELTY: {\n",
    "        'color': 'black',\n",
    "        'label': 'gnovelty+pcl'\n",
    "    },\n",
    "    CPLEX: {\n",
    "        'color': 'purple',\n",
    "        'label': 'CPLEX'\n",
    "    },\n",
    "    SATFC_PLUS_CPLEX: {\n",
    "        'color': 'cyan',\n",
    "        'label': 'SATFC+'\n",
    "    }\n",
    "}\n",
    "\n",
    "dual_standard_analysis(d, 'feasibilitychecker', fc_df)\n",
    "\n",
    "# normalized = False\n",
    "# standard_analysis(d, 'feasibilitychecker123', fc_df.query(f\"type != '{SATFC_PLUS_CPLEX}' and UHF_Only\"))\n",
    "# normalized = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## VHF\n",
    "bd = '/global/scratch/satfc/new_experiments/v6/vhf'\n",
    "folders = glob.glob(f'{bd}*/FCC/*')\n",
    "vhf_df = parse_experiment(folders, skip_failures=True)\n",
    "\n",
    "display(vhf_df.groupby(['model', 'type', 'UHF_Only']).count())\n",
    "\n",
    "vhf_df = vhf_df.reset_index().drop('type', axis=1)\n",
    "vhf_df['type'] = vhf_df.apply(lambda x: 'No VHF' if x['UHF_Only'] else 'FCC', axis=1)\n",
    "vhf_df['UHF_Only'] = True\n",
    "vhf_df = vhf_df.set_index(['type', 'auction'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vhf_df['cputime'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VHF = 'FCC'\n",
    "NO_VHF = 'No VHF'\n",
    "TYPES = [VHF, NO_VHF]\n",
    "FRAMES = make_frames(vhf_df, types=TYPES)\n",
    "\n",
    "\n",
    "d = standard_pallet(TYPES)\n",
    "d[VHF]['label'] = 'With VHF'\n",
    "d[NO_VHF]['label'] = 'Without VHF'\n",
    "\n",
    "\n",
    "dual_standard_analysis(d, 'vhf', vhf_df, types=TYPES)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Bid Processing Algorithm\n",
    "bp_df = parse_experiment(make_folders('/global/scratch/satfc/new_experiments/v6/bidprocessing29'), skip_failures=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "FCC = 'FCC'\n",
    "F2F = 'F2F'\n",
    "F2F30 = 'F2F30'\n",
    "TYPES = [FCC, F2F]\n",
    "print(f\"CPU time for f2f: {bp_df.loc[TYPES]['cputime'].sum()}\")\n",
    "FRAMES = make_frames(bp_df, types=TYPES)\n",
    "\n",
    "d = standard_pallet(TYPES)\n",
    "\n",
    "d[F2F]['label'] = 'First to Finish'\n",
    "d[FCC]['label'] = r'Incentive Auction'\n",
    "# d[F2F30]['label'] = 'First to Finish (0.5hr)'\n",
    "\n",
    "dual_standard_analysis(d, 'bid_processing', bp_df.query('type != \"F2F30\"'), types=TYPES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_df.reset_index().groupby(['type', 'model'])['walltime'].mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
